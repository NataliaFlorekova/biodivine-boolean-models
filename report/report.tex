\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
\usepackage{pgfplots}
\usepackage{tikz}
\linenumbers

\usepackage{newfloat}
\DeclareFloatingEnvironment[name={Online-only Table}]{supptable}

% 110 characters; 68 right now
\title{Comprehensive repository of logically consistent real-world Boolean network models}

\author[1,2]{Samuel Pastva}
\author[2]{David Šafránek}
\author[2]{Nikola Beneš}
\author[1]{Thomas Henzinger}
\author[2]{Luboš Brim}
\affil[1]{Institute of Science and Technology Austria, Klosterneuburg, 3400, Austria}
\affil[2]{Faculty of Informatics, Masaryk University, Brno, 60200, Czechia}

\affil[*]{corresponding author: Samuel Pastva (samuel.pastva@ist.ac.at; xpastva@fi.muni.cz)}

%\affil[$\dag$]{these authors contributed equally to this work}

\newcommand{\todo}[1]{{\color{red} #1}}

% TODOs for final submission:
%  - We should add support for BMA models and ideally resolve as many model issues as possible.
%  - We should include a method that can sample different valuations of model inputs.
%  - We need a Zenodo package for the 2022 edition and a new package for the 2023 edition (including BMA). However, 2022 is good enough for the first ArXiv submission.
%  - For the final submission, we should have a python package that can download and export the data. This should be also part of CoLoMoTo.
%  - Ideally, for the final submission we should have some kind of reaction from biomodels about potential inclusion of these models and the validation pipeline.
%  - Ideally, we should also have some example Jupyter notebooks that show how to analyse the models in tools like trappist or AEON.
%  - Ideally, we should also have the attractor/fixed-point/trap-space data for each model in the 2023 edition.
%  - For the final submission, we should have a "workflow" figure. But we don't need it for ArXiv.

\begin{abstract}
	% 170 word limit; ~157 right now
	Recent developments in both computational analysis and data-driven syntesis enable a new era of automated reasoning with logical models (Boolean networks in particular) in systems biology. However, these advancements also motivate an increased focus on quality control and performance comparisons between tools.
	
	At the moment, to illustrate real-world applicability, authors typically test their approaches on small sets of manually curated models that are inherently limited in scope.
	%, or biologically unrealistic collections of random networks. 
	This further complicates reuse and comparisons, because benchmark models often contain ad hoc modifications or are outright not available.
	
	In this paper, we describe a new, comprehensive, open source dataset of 210+ Boolean network models compiled from available databases and a literature survey. The models are available in a wide range of formats. Furthermore, the dataset is accompanied by a validation pipeline that ensures the integrity and logical consistency of each model. Using this pipeline, we identified and repaired 400+ potential problems in a number of widely used models.
\end{abstract}
\begin{document}

\flushbottom
\maketitle
%  Click the title above to edit the author information and abstract

\thispagestyle{empty}

%\noindent Please note: Abbreviations should be introduced at the first mention in the main text – no abbreviations lists or tables should be included. Structure of the main text is provided below.

\section*{Background \& Summary}

% 700 word limit, no sub-sections; ~450 right now

% Motivation
Logical models in general, and Boolean networks in particular, represent one of the fundament modelling frameworks employed by systems biology~\cite{bn-intro}. Historically, much of the Boolean network design and analysis has been performed either manually, or through computer assisted approaches requiring extensive involvement of domain experts~\cite{bbm-014, bbm-023, bbm-095}. However, recent developments in topics like attractor~\cite{itgr,nfvs,succession-diagrams} and trap space~\cite{trappist} detection, bifurcation analysis~\cite{bifurcation-analysis}, and synthesis from data and prior knowledge~\cite{sketches,bonesis} enable comprehensive automated analysis of large, possibly partially unknown networks comprising hundreds of components.

This proliferation of Boolean network tools and methods motivates the need for extensive and reproducible validation using realistic real-world models. Typically, this role is served by ad hoc subsets of models available in popular systems biology databases such as CellCollective~\cite{cell-collective}, Biomodels~\cite{biomodels} or GINsim~\cite{ginsim}. However, this approach suffers from many obvious downsides. 

While these databases have non-trivial overlap, they are mostly focused on specific human-curated models. As such, they are inherently limited in scope to the models recognised by the database curators. Furthermore, models available from multiple sources often contain subtle but critical modifications in the network structure and initial conditions. Finally, these sources often lack automated validation of the model integrity and logical consistency, meaning errors can propagate to models derived in the future, or go unnoticed when performing analysis.

% Dataset

To address these issues, we present the \emph{Biodivine Boolean Models} (BBM) dataset. BBM covers 210+ models from an extensive set of sources, including the aforementioned databases and independently published models (see Figure~\ref{fig:sources}). For each model, BBM tracks the primary source of the model (i.e. its publication and authors), any secondary sources (e.g. databases) and the source for the actual model files (e.g. git repositories, supplementary materials, database entries, etc.). 

Aside from model aggregation, BBM provides several benefits to tool authors: First, models tracked in BBM are available in several widely recognised formats (\texttt{bnet}~\cite{pyboolnet}, \texttt{aeon}~\cite{aeon}, and \texttt{sbml}~\cite{sbml-qual}) and can be downloaded in bulk. Second, BBM eliminates certain ambiguities in model representation, such as the treatment of network input nodes. Third, BBM performs extensive static validation to ensure logical consistency between variable update rules and the associated influence graph of each model. This process identifies and repairs common problems in logical models such as mismatch in monotonicity of the regulation and the update function, or the presence of (logically) redundant model components. Finally, BBM provides an automated reproducible workflow to generate custom variants of the dataset based on the user provided criteria.

Overall, we believe BBM significantly simplifies the process of validating and benchmarking Boolean network tools as it provides a large, clearly defined and validated set of models. To the best of our knowledge, BBM is also the largest publicly available set of real-world (i.e. not randomly generated) Boolean network models.

% (700 words maximum) An overview of the study design, the assay(s) performed, and the created data, including any background information needed to put this study in the context of previous work and the literature. The section should also briefly outline the broader goals that motivated the creation of this dataset and the potential reuse value. We also encourage authors to include a figure that provides a schematic overview of the study and assay(s) design. The Background \& Summary should not include subheadings. This section and the other main body sections of the manuscript should include citations to the literature as needed. 

\section*{Methods}

In this section, we first give a quick overview of the relevant elements of Boolean network models. We then proceed to list how the actual BBM dataset is created, curated, validated and distributed.

\subsection*{Boolean networks}

% TODO: For final version, it would be nice to have an example here.,

First, let us give a brief formal introduction into the topic of Boolean network modelling. By $\mathbb{B}$, we denote the set $\{0,1\}$. We then say that a \emph{Boolean network} $\mathcal{B}$ over $n$ variables is an indexed collection $\mathcal{B} = \{ F_1, \ldots, F_n \}$, such that each $F_i$ is a Boolean \emph{update function} $F_i  : \mathbb{B}^n \to \mathbb{B}$ (the set of Boolean vectors $\mathbb{B}^n$ is called the \emph{state space} of $\mathcal{B}$). Naturally, within a real-world model, variables are also augmented with human-readable names and other biologically relevant metadata, while functions are described using Boolean expressions or function tables.

\paragraph{Signed Influence graph} Individual update functions typically depend only on a small subset of the network variables, not the whole network state. This fact is communicated using the \emph{signed influence graph} (often also called the \emph{regulatory network}) associated with the Boolean network $\mathcal{B}$. This is a labelled directed graph $\mathcal{I} = (V, E, l)$ such that its vertices are the variables of $\mathcal{B}$, $V = \{ 1, \ldots, n \}$, edges $E \subseteq V \times V$ represent dependencies between variables (we say that $x$ \emph{regulates} $y$ when $(x,y) \in E$) and $l : E \to \{ \oplus, \ominus, ? \}$ labels each edge with an optional \emph{monotonicity} (positive, negative, or unknown). In rare cases, \emph{mixed} monotonicity (combination of $\oplus$ and $\ominus$) is used to signify that the relationship is expected to be non-monotonic. However, for simplicity and due to its rareness, we do not consider such case here and treat such \emph{mixed} labels simply as \emph{unknown}. The influence graph is typically provided directly by model authors.

\paragraph{Properties of Boolean functions} Intuitively, the influence graph $\mathcal{I}$ imposes additional requirements on the structure of the network's update functions $F_i$. Formally, we can understand these requirements as \emph{essentiality} and \emph{monotonicity} of individual function inputs. First, given a state $x \in \mathbb{B}^n$, we write $x[i \gets b]$ to denote a copy of $x$ with the value of the $i$-th variable substituted for $b \in \mathbb{B}$. Then, given a function $F: \mathbb{B}^n \to \mathbb{B}$, we say that the $i$-th variable is an \emph{essential} input of $F$ if the output of $F$ depends on this variable, formally $\exists x \in \mathbb{B}^n.~F(x[i \gets 0]) \not= F(x[i \gets 1])$. We also say that $F$ is \emph{positively monotonic} in its $i$-th input when increasing this input cannot decrease the output of $F$, formally $\forall x \in \mathbb{B}.~F(x[i \gets 0]) \leq F(x[i \gets 1])$. Symmetrically, we say that the input is \emph{negatively monotonic} when $\forall x \in \mathbb{B}.~F(x[i \gets 0]) \geq F(x[i \gets 1])$.

In practice, these essentiality and monotonicity requirements map to the biological assumptions about the modelled system. For example, if a transcription factor is observed to activate the expression of a particular gene in a wet lab experiment, we expect it to act as an essential and positively monotonic input in the corresponding update function of our in silico model. Overall, we expect that the essential inputs of each update function are exactly the regulators declared within the influence graph and that the monotonicity of these inputs matches the associated edge labels $l$.

\subsection*{Model Acquisition}

Next, we describe the process of compiling the BBM dataset. Due to the high variability of model sources, the process of incorporating a new model is largely manual (aside from validation and consistency checking covered in the next section).

\paragraph{Eligible models} 

To admit the widest possible assortment of realistic models, we currently allow submission of any logical model that can be reliably retrieved from a known database, repository, or an associated publication. The only requirement is that the model must be based on a real biological system. That is, we do not accept randomly generated or otherwise synthetic models.  However, we do not require any specific level of curation or validation of any biological claims. In particular, the model can be hand made, automatically synthesised, or anything in between. Similarly, we accept many different model formats and we are willing to assist with translation if a machine-friendly model representation is not available.

\paragraph{Multi-valued networks}

The dataset also incorporates multi-valued networks. That is, logical models admitting multi-valued or bounded integer variables (as opposed to just Booleans). To maximise compatibility with the available tools, every such model is instead provided in a Booleanised representation. That is, the model is transformed into a plain Boolean network such that each multi-valued component with domain $\{ 0, \ldots, k\}$ is expanded into $k$ Boolean components using the well-known Van Ham encoding~\cite{van-ham}. This process is facilitated by the tool \texttt{biolqm}.~\cite{biolqm} Each Booleanised multi-valued model is distinguished using a \texttt{multi-valued} keyword included in the model's metadata. Whenever possible, we also incorporate the \texttt{sbml}~\cite{sbml-qual} representation of the original (i.e. non-Booleanised) multi-valued model. However, such original files currently cannot be processed by the automated validation pipeline.

\paragraph*{Sources} 

As of 2022, the dataset incorporates 212 models from a wide range of publications. Notable sources include GINsim~\cite{ginsim} (83 models), CellCollective~\cite{cell-collective} (78 models), Biomodels~\cite{biomodels} (18 models) and the COVID-19 Disease Map~\cite{bbm-covid-disease-map} (22 models). If a model appears in multiple databases, the dataset lists such model only once with multiple source links, even if there are minor differences between the model files in each database. The contribution of each database to the overall dataset is visualised in Figure~\ref{fig:sources}. Furthermore, Online-only Table~\ref{supp:model-list} gives the full list of models including references to their original publications and Online-only Table~\ref{supp:database-map} maps relevant database entries to the corresponding BBM models. The remaining models are sourced through a comprehensive literature search for Boolean network related keywords across PubMed and Google Scholar.

\subsection*{Normalisation, Validation and Repair}

Within BBM, each model is initially assigned a unique integer identifier (ID) and a human-readable name. Additionally, an \emph{input} model file is required, using one of the eligible formats: \texttt{bnet}~\cite{pyboolnet}, \texttt{aeon}~\cite{aeon}, and \texttt{sbml}~\cite{sbml-qual}. In some cases, such representation is not available. For example, some models are described directly within the text of a supplementary material of a publication. For such models, we perform a manual conversion into one of the supported formats, but we also maintain the original model representation for future reference.

Our automated pipeline then translates the input model file into all three formats and performs several normalisation steps to maximise compatibility with other tools. First, we ensure that all variable names are unique and do not contain any special characters (in particular for \texttt{sbml}, model variables are further distinguished by separate IDs, hence a name can be an arbitrary string). Then, several normalisation and validation steps are performed to ensure the model contains no additional issues.

\paragraph*{Input node normalisation} A variable of a Boolean network is typically called an \emph{input} if it has no incoming regulations (no incoming edges within the influence graph). Consequently, update function of such variable can be only $\mathit{true}$ or $\mathit{false}$, since it cannot have any essential inputs. The particular choice of update functions then constitutes the \emph{initial conditions} of the model. However, some authors also consider inputs to be constant but unknown, meaning their update function is the identity function. In such case, the variable has a positive self-regulation, but this is sometimes omitted if clear from context. The initial conditions of the model (if any) then need to be provided separately. Finally, some tools also allow to omit the update function of input nodes entirely, giving yet another possible representation for constant but unknown inputs.

The distinction between these representations is subtle but crucial in many instances: For example, when considering attractor detection, a constant $\mathit{true}$ or $\mathit{false}$ restricts the search to the specified value. Meanwhile, if the input is constant but unknown, the result covers attractors for every possible combination of input values. The number of attractors thus increases exponentially with the number of inputs in such a scenario.

In our pipeline, we detect the presence of network input nodes and normalise them during export. By default, models are distributed without the update functions on all recognised input nodes. However, using the custom dataset export procedure (discussed in the later \emph{Data Distribution} section), users can chose what representation of inputs best suits their needs (i.e. a constant value, identity update function, or no update function at all).

\paragraph*{Regulation monotonicity and essentiality}

Another step in our pipeline is responsible for validating the declared influence graph of the network against the actual update functions employed by the model. We do this using the symbolic BDD framework within the tool \texttt{aeon.py}~\cite{aeonpy}. This procedure allows us to formally verify the update function properties as described in the \emph{Boolean networks} section. If an inconsistency is found, we manually adjust the influence graph such that the problem is removed, but we note this change in the metadata of the model. As such, the actual Boolean dynamics of the model are unchanged, but the error is recorded for future reference. The following errors can be detected and repaired using this procedure:

\begin{enumerate}
	\item Input $j$ is essential in $F_i$, but there is no edge $(j,i) \in E$ in the influence graph; repaired by adding this regulation edge.
	\item Regulation $(j,i) \in E$ appears in the influence graph, but $j$ is not an essential input of $F_j$; repaired either by removing the regulation edge, or by annotating the regulation as \emph{non-essential} (only some output formats support such annotation).
	\item Regulation $(j,i) \in E$ has a known monotonicity $l(j,i) \in \{\oplus, \ominus\}$, but the input $j$ of $F_i$ does not exhibit this monotonicity; repaired by setting the monotonicity label to $?$ (unknown).
\end{enumerate}

Note that in some instances, these issues may be intentional. For example, if an error of type 2 is detected such that the update function expression does not contain the incriminated variable at all, this could be a mechanism by which the authors specify that the relationship between the two variables is notable, but unused in this particular system. In such case, the \emph{non-essential} annotation is the correct way to resolve this issue.

However, for the vast majority of errors we observed, this is not the case: The type 2 and 3 errors arose primarily from update functions that syntactically contain the problematic variable, but due to the structure of the function, either the variable does not contribute towards the output of the function at all, or the monotonicity of this contribution does not match the monotonicity declared by the authors.

\paragraph*{Unused components}

Finally, we observe that many models admit variables that do not interact with the rest of the model in any meaningful way, or that such variables appear once all input essentiality errors are corrected. In general, we thus validate that the influence graph of the network in question is always weakly connected. That is, between any two variables, there must be some form of a direct or transitive relationship. If such disconnected components are found, we only retain the largest weakly connected component.

\subsection*{Dataset Distribution}

The dataset is managed through a versioned git repository that is continuously updated with new models. However, we regularly publish official \emph{editions} of the dataset which freeze the set of models at a particular time-point and can be referenced separately.

\paragraph*{Model metadata} 

As already discussed, each model within a particular BBM edition is available in three formats, \texttt{bnet}~\cite{pyboolnet}, \texttt{aeon}~\cite{aeon}, and \texttt{sbml}~\cite{sbml-qual}, and with erased update functions on input variables. Furthermore, each model is accompanied by a collection of metadata which is provided both as a machine-friendly \texttt{json} file and a human-readable \texttt{markdown} document. As part of this metadata, we track the publication where the model first appeared (as a BibTeX reference), the original source of the model file, description of any modifications made to the model during validation, as well as the set of relevant keywords.

Using these keywords, we track the databases in which the model appears (e.g. \texttt{cell-collective}, \texttt{ginsim}, etc.) or methods used to construct the model (e.g. \texttt{casq}~\cite{casq}). We also use the keyword \texttt{repaired} to label models where some logical inconsistencies were found during validation (the specific nature of the repair performed is detailed as a separate note), and keyword \texttt{multi-valued} to indicate that the model is a Booleanised version of a multi-valued network.

\paragraph*{Custom datasets}

We recognise that our chosen model representation may not be suitable for all benchmarking and validation tasks. As such, we also include an interactive workflow which allows anyone to export a custom edition based on the BBM dataset. Specifically, this workflow allows the user to:

\begin{itemize}
	\item Chose between the three model formats;
	\item Chose the desired representation of input variables (constant $\mathit{true}$, constant $\mathit{false}$, identity function, erased function);
	\item Filter the results using a custom Python expression evaluated for each model and its metadata.
\end{itemize}

Using this filter functionality, users can pick models based on structural properties (presence of a specific variable or regulation, the number of variables, connectivity, etc.), but also based on model metadata (model authors, keywords, etc.). To ensure reproducibility, each such custom dataset edition incorporates an additional metadata file with all parameters of the workflow, meaning the custom edition can be fully recreated based on this metadata file.

%The Methods should include detailed text describing any steps or procedures used in producing the data, including full descriptions of the experimental design, data acquisition assays, and any computational processing (e.g. normalization, image feature extraction). See the detailed section in our submission guidelines for advice on writing a transparent and reproducible methods section. Related methods should be grouped under corresponding subheadings where possible, and methods should be described in enough detail to allow other researchers to interpret and repeat, if required, the full study. Specific data outputs should be explicitly referenced via data citation (see Data Records and Citing Data, below).

%Authors should cite previous descriptions of the methods under use, but ideally the method descriptions should be complete enough for others to understand and reproduce the methods and processing steps without referring to associated publications. There is no limit to the length of the Methods section. Subheadings should not be numbered.

\section*{Data Records}

There are currently two editions of the BBM dataset, both available as Zenodo archives: edition 2021~\cite{bbm2021} at the address \hyperlink{https://doi.org/10.5281/zenodo.8020272}{https://doi.org/10.5281/zenodo.8020272}, and edition 2022~\cite{bbm2022} at \hyperlink{https://doi.org/10.5281/zenodo.8020309}{https://doi.org/10.5281/zenodo.8020309}. Any future updates to the dataset will be announced using the git repository at \hyperlink{https://github.com/sybila/biodivine-boolean-models}{https://github.com/sybila/biodivine-boolean-models}. Both editions contain the raw input model files, the generated output models and their metadata, as well as any programs necessary to validate the integrity of the models and to generate custom model editions. The models available in the latest edition (2022) are summarised in the Online-only Table~\ref{supp:model-list}.

%The Data Records section should be used to explain each data record associated with this work, including the repository where this information is stored, and to provide an overview of the data files and their formats. Each external data record should be cited numerically in the text of this section, for example \cite{Hao:gidmaps:2014}, and included in the main reference list as described below. A data citation should also be placed in the subsection of the Methods containing the data-collection or analytical procedure(s) used to derive the corresponding record. Providing a direct link to the dataset may also be helpful to readers (\hyperlink{https://doi.org/10.6084/m9.figshare.853801}{https://doi.org/10.6084/m9.figshare.853801}).

%Tables should be used to support the data records, and should clearly indicate the samples and subjects (study inputs), their provenance, and the experimental manipulations performed on each (please see 'Tables' below). They should also specify the data output resulting from each data-collection or analytical step, should these form part of the archived record.

\section*{Technical Validation}

First, to ensure compatibility of model formats, we validate the syntax of each model file using the tool \texttt{aeon.py}~\cite{aeonpy} (some of the input model files even contain minor syntactic errors that had to be corrected). Furthermore, we already described the individual validation steps performed within our pipeline as part of the \emph{Methods} section. This validation pipeline is executed for each commit of the aforementioned git repository, meaning no errors can be introduced into the dataset undetected. 

However, we would like to emphasise the importance of this validation step by analysing the number and types of potential problems uncovered using our validation pipeline. This is summarised in Figure~\ref{fig:errors}, which shows the number of problems grouped by type (with a more detailed breakdown in Online-only Table~\ref{supp:model-list}). Here, the \emph{Other} category mainly covers models with syntactic issues or other obvious typos. What is especially alarming for us is the high number of regulations with invalid monotonicity or essentiality properties. Overall, we found that $\sim1.5\%$ of all regulations have potential integrity problems when compared to the actual update function.

Finally, we should note that our validation still has potential blind spots and the total number of problems thus may not be final. First, the Booleanization process using \texttt{biolqm}~\cite{biolqm} which is applied to multi-valued networks always ``resets'' the network's influence graph such that it is consistent with the Booleanized update functions. Since we currently cannot work with multi-valued networks directly, this means the two most prominent types of errors cannot be detected in these models. Second, many models do not come annotated with a signed influence graph and are only given as a list of functions. For such models, we thus have nothing to validate against. Nevertheless, we could still compare the employed regulations against other models and biological databases where applicable. Our goal is to address these shortcomings as part of the future work. 

%This section presents any experiments or analyses that are needed to support the technical quality of the dataset. This section may be supported by figures and tables, as needed. This is a required section; authors must present information justifying the reliability of their data.

\section*{Usage Notes}

The model files distributed within BBM are compatible with many common tools for Boolean network analysis. In particular, this includes (but is not limited to) the tools available as part of the CoLoMoTo Jupyter notebook environment.~\cite{colomoto-notebook} Specifically, one can use the following tools (in the alphabetical order) to further analyse the properties of the published models:

\begin{itemize}
	\item \texttt{aeon}~\cite{aeon} and \texttt{aeon.py}~\cite{aeonpy} perform symbolic analysis of the asynchronous network dynamics (attractors, fixed-points, reachability) and bifurcation analysis with respect to network inputs and parameters;
	\item \texttt{biolqm}~\cite{biolqm} and \texttt{ginsim}~\cite{ginsim} facilitate analysis of multi-valued models and other miscellaneous methods (translation between additional model formats, simulation, perturbation analysis, etc.);
	\item \texttt{cabean}~\cite{cabean} facilitates target control and reprogramming of the network behaviour;
	\item \texttt{maboss}~\cite{maboss} supports analysis of BNs under \emph{stochastic} update semantics;
	\item \texttt{mpbn}~\cite{mpbn} computes the attractors and reachability properties in the \emph{most-permissive} BN semantics;
	\item \texttt{pyboolnet}~\cite{pyboolnet} supports generation of random networks and synchronous simulation;
	\item \texttt{pystablemotifs}~\cite{pystablemotifs} uses succession diagrams for attractor computation and network reprogramming;
	\item \texttt{trappist}~\cite{trappist} computes the minimal and maximal trap spaces of the network as well as fixed-points.
\end{itemize}

For further reading, we recommend the repository of the CoLoMoTo notebook environment, which contains usage examples for most of the aforementioned tools distributed as user-friendly Jupyter notebooks.

%The Usage Notes should contain brief instructions to assist other researchers with reuse of the data. This may include discussion of software packages that are suitable for analysing the assay data files, suggested downstream processing steps (e.g. normalization, etc.), or tips for integrating or comparing the data records with other datasets. Authors are encouraged to provide code, programs or data-processing workflows if they may help others understand or use the data. Please see our code availability policy for advice on supplying custom code alongside Data Descriptor manuscripts.

%For studies involving privacy or safety controls on public access to the data, this section should describe in detail these controls, including how authors can apply to access the data, what criteria will be used to determine who may access the data, and any limitations on data use. 

\section*{Code availability}

The code, including previous revisions and all relevant model source files, is available as a git repository at the URL \hyperlink{https://github.com/sybila/biodivine-boolean-models}{https://github.com/sybila/biodivine-boolean-models}. Historical revisions of the source code associated with each BBM edition are also part of the aforementioned Zenodo packages. Submissions of new models are encouraged through issues and pull requests in this git repository (see instructions in the \texttt{CONTRIBUTING.md} file). The automated validation and post-processing relies on the tool \texttt{aeon.py}~\cite{aeonpy}, version \texttt{1.1.0}. Furthermore, \texttt{biolqm}~\cite{biolqm} was manually used for some of the initial model conversions, but is not used by the automated validation or the export pipeline.

\bibliography{report}

%\noindent LaTeX formats citations and references automatically using the bibliography records in your .bib file, which you can edit via the project menu. Use the cite command for an inline citation, e.g. \cite{Kaufman2020, Figueredo:2009dg, Babichev2002, behringer2014manipulating}. For data citations of datasets uploaded to e.g. \emph{figshare}, please use the \verb|howpublished| option in the bib entry to specify the platform and the link, as in the \verb|Hao:gidmaps:2014| example in the sample bibliography file. For journal articles, DOIs should be included for works in press that do not yet have volume or page numbers. For other journal articles, DOIs should be included uniformly for all articles or not at all. We recommend that you encode all DOIs in your bibtex database as full URLs, e.g. https://doi.org/10.1007/s12110-009-9068-2.

\section*{Acknowledgements}

This work was partially supported by GACR [grant No. GA22-10845S]; and
Grant Agency of Masaryk University [grant No. MUNI/G/1771/2020]. This project has received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie Grant Agreement No. 101034413.

%Acknowledgements should be brief, and should not include thanks to anonymous referees and editors, or effusive comments. Grant or contribution numbers may be acknowledged.

%\section*{Author contributions statement}

%\todo{TODO}

%Must include all authors, identified by initials, for example:
%A.A. conceived the experiment(s), A.A. and B.A. conducted the experiment(s), C.A. and D.A. analysed the results. All authors reviewed the manuscript. 

\section*{Competing interests}

The authors declare that there are no financial or non-financial competing interests associated with this work.

%The corresponding author is responsible for providing a \href{https://www.nature.com/sdata/policies/editorial-and-publishing-policies#competing}{competing interests statement} on behalf of all authors of the paper. This statement must be included in the submitted article file.

\section*{Figures \& Tables}

%Figures, tables, and their legends, should be included at the end of the document. Figures and tables can be referenced in \LaTeX{} using the ref command, e.g. Figure \ref{fig:stream} and Table \ref{tab:example}. 

%Authors are encouraged to provide one or more tables that provide basic information on the main ‘inputs’ to the study (e.g. samples, participants, or information sources) and the main data outputs of the study. Tables in the manuscript should generally not be used to present primary data (i.e. measurements). Tables containing primary data should be submitted to an appropriate data repository.

%Tables may be provided within the \LaTeX{} document or as separate files (tab-delimited text or Excel files). Legends, where needed, should be included here. Generally, a Data Descriptor should have fewer than ten Tables, but more may be allowed when needed. Tables may be of any size, but only Tables which fit onto a single printed page will be included in the PDF version of the article (up to a maximum of three). 

%Due to typesetting constraints, tables that do not fit onto a single A4 page cannot be included in the PDF version of the article and will be made available in the online version only. Any such tables must be labelled in the text as ‘Online-only’ tables and numbered separately from the main table list e.g. ‘Table 1, Table 2, Online-only Table 1’ etc.

\begin{figure}
	\centering
	\pgfplotsset{width=12cm,compat=1.8}
	\begin{tikzpicture}
		\begin{axis}[
			ybar,
			enlargelimits=0.15,
			legend style={at={(0.5,-0.15)},
				anchor=north,legend columns=-1},
			ylabel={\#models},
			symbolic x coords={GINsim, CellCollective, Disease Map, Biomodels, Other},
			xticklabels={$\shortstack{Cell\\Collective}$,GINsim,$\shortstack{Disase\\Map}$, Biomodels, Other},
			xtick=data,
			ymin=5,
			nodes near coords,
			nodes near coords align={vertical},
			]
			\addplot coordinates {(CellCollective,78) (GINsim,83) (Disease Map,22) (Biomodels,18) (Other,37)};			
			\addplot coordinates {(CellCollective,61) (GINsim,59) (Disease Map,22) (Biomodels,7)};
			\addplot coordinates {(CellCollective,17) (GINsim,24) (Disease Map,0) (Biomodels,11)};
			\legend{total,unique source,shared source}
0		\end{axis}
	\end{tikzpicture}
	\caption{Models of the BBM dataset grouped by the database in which they appear, including the number of models uniquely available in each database and the models shared between multiple sources (see Online-only Table~\ref{supp:database-map} for exact mapping).}
	\label{fig:sources}
\end{figure}

\begin{figure}
	\centering
	\pgfplotsset{width=12cm,height=8cm,compat=1.8}
	\begin{tikzpicture}
		\begin{axis}[
			ybar,
			enlargelimits=0.15,
			legend style={at={(0.5,-0.15)},
				anchor=north,legend columns=-1},
			ylabel={\#problems},
			symbolic x coords={monotonicity, observability, redundant, missing, other},
			xticklabels={$\shortstack{Input\\monotonicity}$,$\shortstack{Input\\essentiality}$,$\shortstack{Disconnected\\variables}$, $\shortstack{Missing\\regulations}$, Other},
			xtick=data,
			ymin=5,
			nodes near coords,
			nodes near coords align={vertical},
			]
			\addplot coordinates {(monotonicity,224) (observability,160) (redundant,29) (missing,19) (other,6)};
			0		\end{axis}
	\end{tikzpicture}
	\caption{Types and multiplicity of individual problems uncovered by the validation step of the BBM pipeline (see Online-only Table~\ref{supp:model-list} for per-model summary).}
	\label{fig:errors}
\end{figure}

\begin{supptable}[h]
	\caption{List of all BBM models, including model ID, name, list of sources, and the corresponding publication. Also contains basic metadata of each model, such as the variable and regulation count.}
	\label{supp:model-list}
\end{supptable}

\begin{supptable}[h]
	\caption{Associates BBM models with database entries. Lists a relevant BBM model reference for each entry in one of the tracked databases. Includes the date at which the model was last updated (in case of versioned database entries).}
	\label{supp:database-map}
\end{supptable}

\end{document}